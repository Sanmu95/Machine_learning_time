```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```

## 线性回归LinearRegression


```python
# 处理数据
data = pd.read_excel("IT行业收入表.xlsx", names=['age', 'salary'])
x_train = data['age'].values.reshape(-1, 1)
y_train = data['salary'].values
```


```python
#训练模型
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(x_train, y_train)
```




    LinearRegression()




```python
#预测结果
y_pred = lr.predict(x_train)
plt.scatter(x_train, y_train)
plt.plot(x_train, y_pred, color='red')
plt.show
print('系数： '+str(lr.coef_[0])+'\n截距： '+str(lr.intercept_))
```

    系数： 2497.1513476046866
    截距： 10143.131966873787




![png](https://i.loli.net/2021/09/11/lX6OKtIAfzJncNS.png)
    



```python
#评估模型
from sklearn.metrics import r2_score
r2 = r2_score(y_train, y_pred)
r2
#1-残差平方和/整体平方和，0~1， 越接近1，拟合情况越好
```




    0.8551365584870814



## 逻辑回归LogisticRegression


```python
#处理数据
data = pd.read_excel("股票客户流失.xlsx", names=['account_fund', 'since_last_time', 'lastmonth_commission', 'total_commission', 'user_time', 'isAborted'])
X = data[['account_fund', 'since_last_time', 'lastmonth_commission', 'total_commission', 'user_time']].values
y = data['isAborted'].values
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
```


```python
#训练模型
from sklearn.linear_model import LogisticRegression
LR = LogisticRegression()
LR.fit(X_train, y_train)
```




    LogisticRegression()




```python
#预测结果及准确度
y_pred = LR.predict(X_test)
y_pred_proba = LR.predict_proba(X_test)
from sklearn.metrics import accuracy_score
score = accuracy_score(y_pred, y_test)
print('系数： '+str(lr.coef_)+'\n截距： '+str(lr.intercept_)+'\n分类概率： '+str(y_pred_proba)+'\n准确度： '+str(score))
```

    系数： [2497.1513476]
    截距： 10143.131966873787
    分类概率： [[0.84945292 0.15054708]
     [0.95334791 0.04665209]
     [0.80792957 0.19207043]
     ...
     [0.13403126 0.86596874]
     [0.90191944 0.09808056]
     [0.67221187 0.32778813]]
    准确度： 0.7827733080927591



```python
#评估模型
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred))
from sklearn.metrics import roc_curve
fpr, tpr, rate = roc_curve(y_test, y_pred_proba[:, 1])
plt.plot(fpr, tpr)
plt.show
from sklearn.metrics import roc_auc_score
auc = roc_auc_score(y_test, y_pred_proba[:, 1])
print(auc)
KS = max(tpr-fpr)
print(KS)
```

    [[1421  126]
     [ 333  233]]
    0.8080931747529128
    0.47098567614052955




![png](https://i.loli.net/2021/09/11/rYaqBFP1HD5Xjuc.png)
    


## 决策树DecisionTreeClassifier


```python
#处理数据
data = pd.read_excel('员工离职预测模型.xlsx', names=['salary', 'satisfiction', 'rating', 'pro_number', 'month_work_hour', 'working_ages', 'resigned'])
data.replace({'salary':{'低':0, '中':1, '高':2}}, inplace=True)
X = data.drop('resigned', axis=1)
y = data['resigned']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
```


```python
#模型调参
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
para = {'max_depth':[5,7,9,11,13], 'criterion':['gini', 'entropy'], 'min_samples_split':[5,7,9,11,13,15]}
dtc = DecisionTreeClassifier()
gs = GridSearchCV(dtc, para, scoring='roc_auc', cv=10)
gs.fit(X_train, y_train)
gs.best_params_
```




    {'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 15}




```python
#模型训练
dtc = DecisionTreeClassifier(max_depth=13, criterion='entropy', min_samples_split=15)
dtc.fit(X_train, y_train)
y_pred = dtc.predict(X_test)
proba = dtc.predict_proba(X_test)
df = pd.DataFrame()
df['pred'] = y_pred
df[['proba_0', 'proba_1']] = proba
df
```

![image-20210911200619706](https://i.loli.net/2021/09/11/OKNR5DlnLZaTkjQ.png)


```python
#模型评估
from sklearn.model_selection import cross_val_score
score = cross_val_score(dtc, X_train, y_train, cv=10)
from sklearn.metrics import roc_auc_score
auc_score = roc_auc_score(y_test, proba[:, 1])
from sklearn.metrics import roc_curve
fpr, tpr, tre = roc_curve(y_test, proba[:, 1])
df = pd.DataFrame()
df['fpr'] = fpr
df['tpr'] = tpr
df['tre'] = tre
df
```

![image-20210911200700410](https://i.loli.net/2021/09/11/Xa7Pw8LKzTjn9cx.png)


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


# 朴素贝叶斯GaussianNB


```python
#准备数据
data = pd.read_excel('肿瘤数据.xlsx', names=['circum', 'max_sunken', 'avg_sunken', 'max_area', 'max_radius', 'avg_gray', 'isTumour'])
from sklearn.model_selection import train_test_split
X = data.drop('isTumour', axis=1)
y = data['isTumour']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
```


```python
#训练模型
from sklearn.naive_bayes import GaussianNB
gn = GaussianNB()
gn.fit(X_train, y_train)
```




    GaussianNB()




```python
#模型预测
y_pred = gn.predict(X_test)
gn.score(X_test, y_test)
```




    0.9473684210526315



# K近邻KNeighborsClassifier


```python
#准备数据
data = pd.read_excel('手写字体识别.xlsx')
data.rename(columns={'对应数字':'isNum'}, inplace=True)
X = data.iloc[:, 1:]
y = data.iloc[:, 1]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
```


```python
#模型训练
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
```




    KNeighborsClassifier()




```python
#模型预测
y_pred = knn.predict(X_test)
knn.score(X_test, y_test)
```




    1.0

